{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python vs. Numpy vs. TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces some of the concepts in numerical computing in Python. More specifically, it will go through a very simple example of reducing table sums, first with vanilla Python loops, and then with Numpy and TensorFlow, and compare the performance of those two together.\n",
    "\n",
    "The goal is to get a sense of why we use libraries such as Numpy/TensorFlow, and understand how the basics of how those are implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Imports, constant, and some other setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from functools import partial\n",
    "import timeit\n",
    "from benchmarks import (\n",
    "    TableTestNp, \n",
    "    TableTestPy,\n",
    "    TableTestTf,\n",
    "    NnTestNp,\n",
    "    NnTestTf,\n",
    "    nn_data_generator,\n",
    ")\n",
    "from visualization import plot_with_legend\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "\n",
    "DEFAULT_DTYPE = np.float64\n",
    "TIMEIT_RUNS = 10\n",
    "TIMEIT_REPEATS = 10\n",
    "TEST_SIZES = [10 * 2**x for x in range(1, 8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python vs. Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by comparing vanilla Python with Numpy.\n",
    "\n",
    "Suppose you're building the tables for category-category analyses as shown in this [Statwing demo](https://www.statwing.com/demos/survey#workspaces/127054), and you have been given the **body** of the table as counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                                                Career / Job Satisfaction                                                    |\n",
    "|------------------------|-------------|---------------------|-----------------|-------------------------|---------------------|\n",
    "| Purchasing Budget      | Love my job | Enjoy going to work | It's a paycheck | I'm not happy in my job | Hate my job | Total |\n",
    "| (< \\$1,000)            |          20 |                 35  |              11 |                     12  |           4 |    82 |\n",
    "| (\\$1,001 - \\$5,000)    |          33 |                 39  |              15 |                      4  |           2 |    93 |\n",
    "| (\\$5,001 - \\$25,000)   |          20 |                 22  |               9 |                      3  |           0 |    54 |\n",
    "| (\\$25,001 - \\$100,000) |          11 |                 11  |               3 |                      1  |           0 |    26 |\n",
    "| (> \\$100,000)          |          16 |                 10  |               6 |                      0  |           1 |    33 |\n",
    "| (Don't know)           |          66 |                 195 |              54 |                     24  |           7 |   346 |\n",
    "| Total                  |         166 |                 312 |              98 |                      44 |          14 |   634 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [\n",
    "  [20, 35, 11, 12, 4],\n",
    "  [33, 39, 15, 4, 2,],\n",
    "  [20, 22, 9, 3, 0],\n",
    "  [11, 11, 3, 1, 0],\n",
    "  [16, 10, 6, 0, 1],\n",
    "  [66, 195, 54, 24, 7],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this table, we want to compute the data needed for different table views (\"Count\", \"All %\", \"Row %\", \"Col %\").\n",
    "\n",
    "Let's start with the \"Count\" view. That means that the only things we have to compute are the row, col, and total sums.\n",
    "\n",
    "First, consider a case where you would have to do this with vanilla python for-loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_sums_py(table):\n",
    "    num_rows, num_cols = len(table), len(table[0])\n",
    "\n",
    "    row_sums = [0 for _ in range(num_rows)]\n",
    "    col_sums = [0 for _ in range(num_cols)]\n",
    "    total_sum = 0\n",
    "\n",
    "    for i, row in enumerate(table):\n",
    "        for j, cell in enumerate(row):\n",
    "            # TODO: implement this\n",
    "            col_sums[j] += table[i][j]\n",
    "            row_sums[i] += table[i][j]\n",
    "            total_sum += table[i][j]\n",
    "\n",
    "    return row_sums, col_sums, total_sum\n",
    "\n",
    "row_sums, col_sums, total_sum = table_sums_py(table)\n",
    "\n",
    "assert(row_sums == [82, 93, 54, 26, 33, 346])\n",
    "assert(col_sums == [166, 312, 98, 44, 14])\n",
    "assert(total_sum == 634)\n",
    "\n",
    "print(\"row_sums: \", row_sums)\n",
    "print(\"col_sums: \", col_sums)\n",
    "print(\"total_sum: \", total_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was simple. Now, let's see how the same thing is done with numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy\n",
    "[Numpy](http://www.numpy.org/) is one of the fundamental libraries for scientific computing in Python. Numpy provides high-performance multidimensional array/matrix/tensor objects, and a set of tools and functions for working with these arrays.\n",
    "\n",
    "#### Why?\n",
    "The main benefits of numpy are **speed** and **convenience** for numerical/scientific computing in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an numpy array (np.ndarray) object from the table\n",
    "table_np = np.array(table)\n",
    "\n",
    "# Sanity check\n",
    "assert(np.all(table == table_np))\n",
    "\n",
    "print(\"table: \\n\", table_np)\n",
    "print(\"shape:\", table_np.shape)\n",
    "print(\"type:\", type(table_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then calculate the sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_sums_np(table_np):\n",
    "    row_sums_np = np.sum(table_np, axis=1)\n",
    "    col_sums_np = np.sum(table_np, axis=0)\n",
    "    total_sum_np = np.sum(table_np)\n",
    "    \n",
    "    return row_sums_np, col_sums_np, total_sum_np\n",
    "\n",
    "row_sums_np, col_sums_np, total_sum_np = table_sums_np(table_np)\n",
    "    \n",
    "assert(np.all(row_sums_np == row_sums))\n",
    "assert(np.all(col_sums_np == col_sums))\n",
    "assert(total_sum_np == total_sum)\n",
    "\n",
    "print(\"row_sums: \", row_sums_np)\n",
    "print(\"col_sums: \", col_sums_np)\n",
    "print(\"total_sum: \", total_sum_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy allowed us to do each of the three calculations with `np.sum` function instead of having to write double for-loop as in vanilla python. One of the benefit's of numpy is that it implements many of the functions often needed in numerical computing.\n",
    "\n",
    "But the reason we use numpy is actually its performance. Numpy datastructures are implemented on C-level through python's C-api, which makes them extremely fast compared to vanilla python for-loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's benchmark the two implementations. `TableTestNp` and `TableTestPy` classes are simple python `timeit.Timer` wrappers for testing the performance the functions with different table sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_sizes = [10 * 2**x for x in range(1, 8)]\n",
    "timer_np = TableTestNp(timeit_fn=table_sums_np)\n",
    "times_np = timer_np.repeat(verbose=True, table_sizes=table_sizes)\n",
    "\n",
    "timer_py = TableTestPy(timeit_fn=table_sums_py)\n",
    "times_py = timer_py.repeat(verbose=True, table_sizes=table_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"python\": times_py,\n",
    "    \"numpy\": times_np\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_with_legend([results], figure_idx=1, show=True)\n",
    "plot_with_legend([{\"numpy\": results[\"numpy\"]}], figure_idx=1, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is numpy faster?\n",
    "\n",
    "* *Numpy provides high-performance multidimensional array/matrix/tensor objects*\n",
    "  1. Strict typing for the arrays\n",
    "    * Efficiency/performance vs. flexibility\n",
    "  2. The array operations are run on C-level\n",
    "  3. (1) and (2) enable [vectorization](https://en.wikipedia.org/wiki/Vector_processor), [pipelining](https://en.wikipedia.org/wiki/Instruction_pipelining) etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow\n",
    "So far we have talked about vanilla Python vs. Numpy arrays. In scientific computing scene, everyone talks about TensorFlow.\n",
    "\n",
    "TensorFlow is an open source software library for numerical computation. Unlike Numpy, TensorFlow presents computation using **data flow graphs**. The data flow graph consists of **nodes**, which represent **mathematical operations**, and **edges**, which represent the **multidimensional data arrays** (tensors) flowing between them.\n",
    "\n",
    "#### Why?\n",
    "The flexibility of data flow graphs allow TensorFlow graphs to be easily deployed one or more CPUs or GPUs in various different platforms, such as desktop, server, or mobile device.\n",
    "\n",
    "Thus, TensorFlow -- like Numpy, but in a bit different way -- brings **speed** and **convenience** for numerical/scientific computing in Python.\n",
    "\n",
    "\"Originally ... at Google ... for the purposes of conducting machine learning and deep neural networks research, but the system is general enough to be applicable in a wide variety of other domains as well.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_sums_tf_graph(table_np, dtype=DEFAULT_DTYPE):\n",
    "    \"\"\"Generate tf data flow graph for table sums\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table_np: table of type np.ndarray format\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    ops: list of tensorflow operations (nodes in the graph)\n",
    "      that can be evaluated\n",
    "    feed_dict: dictionary of format { <tf.placeholder>: raw_values }\n",
    "      that can be passed to session.run when evaluating values\n",
    "    \"\"\"\n",
    "    table_tf = tf.constant(table_np, dtype=dtype)\n",
    "\n",
    "    row_sums_sym = tf.reduce_sum(table_tf, axis=1)\n",
    "    col_sums_sym = tf.reduce_sum(table_tf, axis=0)\n",
    "    total_sum_sym = tf.reduce_sum(table_tf)\n",
    "    \n",
    "    ops = (row_sums_sym, col_sums_sym, total_sum_sym)\n",
    "    \n",
    "    return ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops = table_sums_tf_graph(table_np)\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    (row_sums_tf, col_sums_tf, total_sum_tf) = session.run(ops)\n",
    "\n",
    "assert(np.all(row_sums_tf == row_sums))\n",
    "assert(np.all(col_sums_tf == col_sums))\n",
    "assert(total_sum_tf == total_sum)\n",
    "\n",
    "print(\"row_sums: \", row_sums_tf)\n",
    "print(\"col_sums: \", col_sums_tf)\n",
    "print(\"total_sum: \", total_sum_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer_tf = TableTestTf(timeit_fn=table_sums_tf_graph)\n",
    "times_tf = timer_tf.repeat(verbose=True, table_sizes=table_sizes)\n",
    "results[\"tensorflow\"] = times_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_without_python = {k:v for k, v in results.items() if k != 'python'}\n",
    "plot_with_legend([results, results_without_python], figure_idx=2, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is Numpy still faster?\n",
    "Because .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_and_grads_np(data, batch_size):\n",
    "    \"\"\"Create tf operations for computing nn loss and gradients\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    data: array of numpy arrays for (X, y, W1, b1, W2, b2)\n",
    "    \"\"\"\n",
    "    X, y, W1, b1, W2, b2 = data\n",
    "    y = np.argmax(y, axis=1)\n",
    "    N, D = X.shape\n",
    "    \n",
    "    # Assume that N is divisible by batch_size\n",
    "#     for batch in range(N / batch_size):\n",
    "#         s, e = batch*batch_size, batch*(batch_size+1) # start, end\n",
    "#         X_b = X[s,e]\n",
    "#         y_b = y[s,e]\n",
    "#         W1_b = W1[s,e]\n",
    "#         b1_b = b1[s,e]\n",
    "#         W2_b = W2[s,e]\n",
    "#         b2_b = b2[s,e]\n",
    "\n",
    "    # TODO: replace X, y, etc with X_b, y_b etc\n",
    "    \n",
    "    # Compute the forward pass\n",
    "    z = np.dot(X, W1) + b1\n",
    "    h1 = np.maximum(z, 0)\n",
    "    scores = np.dot(h1, W2) + b2\n",
    "    \n",
    "    if y is None: return scores\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = None\n",
    "    \n",
    "    c = np.max(scores, axis=-1, keepdims=True)\n",
    "    # subtract the max element for numerical stability\n",
    "    exp_scores = np.exp(scores - c)\n",
    "    sum_exp_scores = np.sum(exp_scores, axis=1, keepdims=True) # (N, 1)\n",
    "    probs = exp_scores / sum_exp_scores # (N, C)\n",
    "    correct_probs = np.choose(y, probs.T) # (N, 1)\n",
    "    \n",
    "    loss = (np.sum(-np.log(correct_probs)) / float(N)\n",
    "            + 0.5 * (np.sum(W1 * W1) + np.sum(W2 * W2)))\n",
    "    \n",
    "    dscores = probs\n",
    "    dscores[np.arange(N), y] -= 1.0\n",
    "    dscores /= float(N)\n",
    "    \n",
    "    dW2 = np.dot(h1.T, dscores) + W2\n",
    "    db2 = np.sum(dscores, axis=0)\n",
    "    \n",
    "    dh1 = np.dot(dscores, W2.T)\n",
    "    \n",
    "    # grad for ReLU\n",
    "    dz = (z > 0.0) * dh1\n",
    "    \n",
    "    dW1 = np.dot(X.T, dz) + W1\n",
    "    db1 = np.sum(dz, axis=0)\n",
    "    \n",
    "    grads = [dW1, db1, dW2, db2]\n",
    "    \n",
    "    return loss, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_and_grads_tf(data, batch_size, reg=0.0):\n",
    "    \"\"\"Create tf operations for computing nn loss and gradients\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    data: array of numpy arrays for (X, y, W1, b1, W2, b2)\n",
    "    \"\"\"\n",
    "    num_classes = data[1].shape\n",
    "    X, y, W1, b1, W2, b2 = [tf.constant(var) for var in data]\n",
    "    \n",
    "    # Compute the forward pass\n",
    "    z = tf.matmul(X, W1) + b1\n",
    "    h1 = tf.nn.relu(z)\n",
    "    scores = tf.matmul(h1, W2) + b2\n",
    "    \n",
    "    if y is None: return scores\n",
    "    \n",
    "    # Compute the loss\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        logits=scores, labels=y)\n",
    "    loss = (tf.reduce_mean(cross_entropy)\n",
    "            + tf.nn.l2_loss(W1) + tf.nn.l2_loss(W2))\n",
    "\n",
    "    grads = tf.gradients(loss, [W1, b1, W2, b2])\n",
    "    \n",
    "    ops = (loss, grads)\n",
    "    \n",
    "    return ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# N_CLASSES = 10\n",
    "# BATCH_SIZE = 100\n",
    "# X = np.random.rand(BATCH_SIZE, 100)\n",
    "# # y = np.zeros((BATCH_SIZE, N_CLASSES)).astype(np.int64)\n",
    "# # y[np.arange(BATCH_SIZE), np.random.randint(0, N_CLASSES-1, (BATCH_SIZE,))] = 1\n",
    "# y = np.random.randint(0, N_CLASSES-1, (BATCH_SIZE,))\n",
    "\n",
    "# W1 = np.random.rand(100, 100)\n",
    "# b1 = np.random.rand(100,)\n",
    "# W2 = np.random.rand(100, 10)\n",
    "# b2 = np.random.rand(10,)\n",
    "\n",
    "# params = [W1, b1, W2, b2]\n",
    "\n",
    "data = (X, y, W1, b1, W2, b2) = nn_data_generator()\n",
    "\n",
    "loss_np, grads_np = loss_and_grads_np(data, 32)\n",
    "loss_tf_sym, grads_tf_sym = loss_and_grads_tf(data, 32)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    loss_tf, grads_tf = session.run([loss_tf_sym, grads_tf_sym])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.allclose(loss_tf, loss_np)\n",
    "assert np.all([\n",
    "    grad_tf.shape == grad_np.shape == d.shape\n",
    "    for grad_tf, grad_np, d in zip(grads_tf, grads_np, data[2:]) ])\n",
    "assert np.all([\n",
    "        np.allclose(grad_tf, grad_np)\n",
    "        for grad_tf, grad_np in zip(grads_tf, grads_np) ])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
